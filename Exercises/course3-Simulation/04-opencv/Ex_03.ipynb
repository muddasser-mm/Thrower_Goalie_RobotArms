{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Add REAL WORLD configuration and camera\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")\n",
    "\n",
    "# Change object color in RealWorld to red (should add)\n",
    "obj1 = RealWorld.frame(\"obj1\")\n",
    "obj1.setColor([1.,.0,.0])\n",
    "\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile('../../scenarios/pandasTable.g')\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the focal length\n",
    "f = 0.895\n",
    "f = f * 360.\n",
    "#the relative pose of the camera\n",
    "# pcl.setRelativePose('d(-90 0 0 1) t(-.08 .205 .115) d(26 1 0 0) d(-1 0 1 0) d(6 0 0 1) ')\n",
    "fxfypxpy = [f, f, 320., 180.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "tau = .005\n",
    "\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        \n",
    "        # Convert depth to point cloud. (n*3) shape\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        \n",
    "        # Convert BGR to RGB. Then to only detect changes, only gray scale enough\n",
    "        frame = cv.cvtColor(rgb, cv.COLOR_BGR2RGB)\n",
    "        frame_g = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Blurr, so not to detect minute differences and noise in each consecutive frame\n",
    "        # Gaussian blurr 21 X 21\n",
    "        # frame_blurr = cv.GaussianBlur(frame_g, (21, 21), 0)\n",
    "\n",
    "        # If the first frame is None, initialize it\n",
    "        if firstFrame is None:\n",
    "            firstFrame = frame_g\n",
    "            continue\n",
    "\n",
    "        # compute the absolute difference between the current frame and\n",
    "        # first frame\n",
    "        frame_diff = cv.absdiff(firstFrame, frame_g)\n",
    "\n",
    "        # If difference is larger than 25 then consider the change\n",
    "        # retval, dst=cv.threshold(src, thresh, maxval, type[, dst])\n",
    "        _, frame_thresh = cv.threshold(frame_diff, 30, 255, cv.THRESH_BINARY)\n",
    "\n",
    "        # Dilate the thresholded image to fill in holes, then find contours on thresholded image\n",
    "        frame_dil = cv.dilate(frame_thresh, None, iterations=2)\n",
    "\n",
    "        # Find contours\n",
    "        frame_contours, _ = cv.findContours(frame_dil, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw contours for all objects detected\n",
    "        output_frame = frame.copy()\n",
    "        for contour in frame_contours:\n",
    "            # If contour area too small ignore it\n",
    "            # if cv.contourArea(contour) < 200:\n",
    "                #continue\n",
    "\n",
    "            # Draw contour\n",
    "            # image =cv.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]])\n",
    "            cv.drawContours(output_frame, contour, -1, (0, 255, 0), 3)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        if len(frame)>0:cv.imshow('Input_Frame',frame)\n",
    "        if len(frame_diff)>0:cv.imshow('Diff_Frame',frame_diff)\n",
    "        #if len(frame_thresh)>0:cv.imshow('Threshold_Frame',frame_thresh)\n",
    "        if len(output_frame)>0:cv.imshow('Output_Frame',output_frame)\n",
    "\n",
    "        # Setting the object in the config space, as point cloud\n",
    "        cameraFrame.setPointCloud(points, rgb)\n",
    "        \n",
    "        # updating the display\n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    S.step([], tau, ry.ControlMode.none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "tau = .005\n",
    "\n",
    "# initialize the first frame in the video stream\n",
    "InitialDepth = None\n",
    "maxdepth = 0\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        \n",
    "        # Convert BGR to RGB.\n",
    "        frame = cv.cvtColor(rgb, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert depth to point cloud. (n*3) shape\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "\n",
    "        # If the first frame is None, initialize it\n",
    "        if InitialDepth is None:\n",
    "            maxdepth = np.amax(depth)\n",
    "            InitialDepth = (np.floor((depth.astype(np.float64) / maxdepth) * 255)).astype(np.uint8)\n",
    "            continue\n",
    "\n",
    "        # Normalise ans scale depth array\n",
    "        depth_NS = (np.floor((depth.astype(np.float64) / maxdepth) * 255)).astype(np.uint8)\n",
    "        \n",
    "        # compute the absolute difference between the current frame and\n",
    "        # first frame\n",
    "        depth_diff = InitialDepth - depth_NS\n",
    "        # Set my output imgage pixel value to zero everywhere except my mask\n",
    "        depth_diff = depth_diff.clip(min=0)\n",
    "        #depth_diff = cv.absdiff(InitialDepth, depth_NS)\n",
    "\n",
    "        # If difference is larger than 25 then consider the change\n",
    "        # retval, dst=cv.threshold(src, thresh, maxval, type[, dst])\n",
    "        _, depth_thresh = cv.threshold(depth_diff, 25, 255, cv.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        depth_contours, _ = cv.findContours(depth_thresh, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Draw contours for all objects detected\n",
    "        output_frame = frame.copy()\n",
    "        for contour in depth_contours:\n",
    "            # If contour area too small ignore it\n",
    "            # if cv.contourArea(contour) < 200:\n",
    "                #continue\n",
    "\n",
    "            # Draw contour\n",
    "            # image =cv.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]])\n",
    "            cv.drawContours(output_frame, contour, -1, (0, 255, 0), 3)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        if len(frame)>0:cv.imshow('Input_Frame',frame)\n",
    "        if len(depth)>0: cv.imshow('Depth_Frame', 0.5* depth)\n",
    "        if len(depth_diff)>0:cv.imshow('Diff_Frame',depth_diff)\n",
    "        if len(depth_thresh)>0:cv.imshow('Threshold_Frame',depth_thresh)\n",
    "        if len(output_frame)>0:cv.imshow('Output_Frame',output_frame)\n",
    "\n",
    "        # Setting the object in the config space, as point cloud\n",
    "        cameraFrame.setPointCloud(points, rgb)\n",
    "        \n",
    "        # updating the display\n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    S.step([], tau, ry.ControlMode.none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.destroyAllWindows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-5e80401329f2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-5e80401329f2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    return arr = np.floor((arr / maxm) * 255)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def scale_normalise(arr, maxm):\n",
    "    return arr = np.floor((arr / maxm) * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(rgb)>0: cv.imshow('OPENCV - rgb', rgb)\n",
    "# if len(depth)>0: cv.imshow('OPENCV - depth', 0.5* depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example to grap images from a webcam\n",
    "(but this only gives you an rgb, not depth)\n",
    "hit 'q' in the window to stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 1 - Static Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width =  800 Height =  800\n"
     ]
    }
   ],
   "source": [
    "# Ex 1 - For static image\n",
    "# Load an color image as HSV\n",
    "\n",
    "in_img = cv.imread('images/all24.jpg')\n",
    "height = np.size(in_img, 0)\n",
    "width  = np.size(in_img, 1)\n",
    "\n",
    "print (\"Width = \", width, \"Height = \", height )\n",
    "\n",
    "# converting from BGR to HSV color space\n",
    "hsv_img = cv.cvtColor(in_img,cv.COLOR_BGR2HSV)\n",
    "\n",
    "# Ex 1.1 - Filter the color of the image to find all pixels that are redish.\n",
    "\n",
    "# Threshold the HSV image, keep only the red pixels\n",
    "red_lowerth = np.array([0,100,90])\n",
    "red_upperth = np.array([10,255,255])\n",
    "red_mask1 = cv.inRange(hsv_img, red_lowerth, red_upperth)\n",
    " \n",
    "# Range for upper range\n",
    "red_lowerth = np.array([160,100,90])\n",
    "red_upperth = np.array([180,255,255])\n",
    "red_mask2 = cv.inRange(hsv_img,red_lowerth,red_upperth)\n",
    "\n",
    "# Generating the final mask to detect red color and find all pixels that are \n",
    "red_mask = cv.addWeighted(red_mask1, 1, red_mask2, 1, 0)\n",
    "\n",
    "# Ex 1.2 - Display the binary image that indicates red pixels.\n",
    "# Set my output imgage pixel value to zero everywhere except my mask\n",
    "output_img = in_img.copy()\n",
    "output_img[np.where(red_mask==0)] = 0\n",
    "\n",
    "cv.imshow(\"Red_Masked_Image\",output_img)\n",
    "\n",
    "# Ex 1.3 - Fit contours to this binary image, which returns the segments.\n",
    "\n",
    "# Find contours for the objects detected in mask\n",
    "# contours, hierarchy=cv.findContours(image, mode, method[, contours[, hierarchy[, offset]]])\n",
    "contours, _ = cv.findContours(red_mask, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    \n",
    "# Ex 1.4 - Display the contours by drawing them into the original RGB image\n",
    "# Draw contours for all objects detected\n",
    "output_img = in_img.copy()\n",
    "for contour in contours:\n",
    "    # If contour area too small ignore it\n",
    "    # if abs(cv.contourArea(contour)) < 10000:\n",
    "        # continue\n",
    "    # image\t=cv.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]])\n",
    "    cv.drawContours(output_img, contour, -1, (0, 255, 0), 3)\n",
    "    \n",
    "cv.imshow(\"Contoured Objects\", output_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 1 - Webcam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 1 - For webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "while(True):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # converting from BGR to HSV color space\n",
    "    hsv_img = cv.cvtColor(frame,cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Ex 1.1 - Filter the color of the image to find all pixels that are redish.\n",
    "    # Threshold the HSV image, keep only the red pixels\n",
    "    red_lowerth = np.array([0,105,70])\n",
    "    red_upperth = np.array([10,255,255])\n",
    "    red_mask1 = cv.inRange(hsv_img, red_lowerth, red_upperth)\n",
    "\n",
    "    # Range for upper range\n",
    "    red_lowerth = np.array([170,105,70])\n",
    "    red_upperth = np.array([180,255,255])\n",
    "    red_mask2 = cv.inRange(hsv_img,red_lowerth,red_upperth)\n",
    "\n",
    "    # Generating the final mask to detect red color and find all pixels that are \n",
    "    red_mask = cv.addWeighted(red_mask1, 1, red_mask2, 1, 0)\n",
    "\n",
    "    # Ex 1.2 - Display the binary image that indicates red pixels.\n",
    "    # Set my output imgage pixel value to zero everywhere except my mask\n",
    "    output_mask = frame.copy()\n",
    "    output_mask[np.where(red_mask==0)] = 0\n",
    "\n",
    "    # Ex 1.3 - Fit contours to this binary image, which returns the segments.\n",
    "    # Find contours for the objects detected in mask\n",
    "    # contours, hierarchy=cv.findContours(image, mode, method[, contours[, hierarchy[, offset]]])\n",
    "    contours, _ = cv.findContours(red_mask, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Ex 1.4 - Display the contours by drawing them into the original RGB image\n",
    "    # Draw contours for all objects detected\n",
    "    output_frame = frame.copy()\n",
    "    for contour in contours:\n",
    "        # If contour area too small ignore it\n",
    "        # if cv2.contourArea(c) < :\n",
    "        #    continue\n",
    "        # image =cv.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]])\n",
    "        cv.drawContours(output_frame, contour, -1, (0, 255, 0), )\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    if len(frame)>0:cv.imshow('Input_Frame',frame)\n",
    "    if len(output_mask)>0:cv.imshow('Output_Mask',output_mask)\n",
    "    if len(output_frame)>0:cv.imshow('Output_Frame',output_frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 2 - Over a video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2 - \n",
    "# cap = cv.VideoCapture(0)\n",
    "cap = cv.VideoCapture('images/car-overhead-1.avi')\n",
    "\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If the frame could not be grabbed, then we have reached the end of the video\n",
    "    if frame is None:\n",
    "        break\n",
    "        \n",
    "    # To only detect changes, gray scale enough\n",
    "    frame_g = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Blurr, so not not detect minute differences and noise in each consecutive frame\n",
    "    # Gaussian blurr 21 X 21\n",
    "    frame_blurr = cv.GaussianBlur(frame_g, (21, 21), 0)\n",
    "    \n",
    "    # 2.1 Store the first image as background image. (Or average over several first images.)\n",
    "    # If the first frame is None, initialize it\n",
    "    if firstFrame is None:\n",
    "        firstFrame = frame_g\n",
    "        continue\n",
    "    \n",
    "    # 2.2 For every new image filter those pixels, that are significantly different to the background.\n",
    "    # Compute the absolute difference between the current frame and\n",
    "    frame_diff = cv.absdiff(firstFrame, frame_g)\n",
    "    \n",
    "    # 2.6. Test the same pipeline, but first smoothing/blurring the image\n",
    "    # If difference is larger than 25 then consider the change\n",
    "    # retval, dst=cv.threshold(src, thresh, maxval, type[, dst])\n",
    "    _, frame_thresh = cv.threshold(frame_diff, 25, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    # Dilate the thresholded image to fill in holes, then find contours on thresholded image\n",
    "    frame_dil = cv.dilate(frame_thresh, None, iterations=2)\n",
    "    \n",
    "    # 2.4. Fit contours to this binary image, which returns the segments.\n",
    "    # Find contours\n",
    "    frame_contours, _ = cv.findContours(frame_dil, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 2.5. Display the contours by drawing them into the original RGB image\n",
    "    # Draw contours for all objects detected\n",
    "    output_frame = frame.copy()\n",
    "    for contour in frame_contours:\n",
    "        # If contour area too small ignore it\n",
    "        if cv.contourArea(contour) < 200:\n",
    "            continue\n",
    "        \n",
    "        # Draw contour\n",
    "        # image =cv.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]])\n",
    "        cv.drawContours(output_frame, contour, -1, (0, 255, 0), 3)\n",
    "        \n",
    "    # Display the resulting frame\n",
    "    if len(frame)>0:cv.imshow('Input_Frame',frame)\n",
    "        \n",
    "    # 2.3. Display the binary image that indicates change pixels.\n",
    "    if len(frame_diff)>0:cv.imshow('Diff_Frame',frame_diff)\n",
    "        \n",
    "    #if len(frame_thresh)>0:cv.imshow('Threshold_Frame',frame_thresh)\n",
    "    if len(output_frame)>0:cv.imshow('Output_Frame',output_frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        # When everything done, release the capture\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
